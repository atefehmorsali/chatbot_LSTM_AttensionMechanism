{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a Chatbot\n",
    "\n",
    "### Use bidirectional LSTM and attention mechanism \n",
    "### Dataset: [Movie Dialogue Corpus](https://www.cs.cornell.edu/~cristian/Cornell_Movie-Dialogs_Corpus.html)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "movie_lines = open('dataset/movie_lines.txt', encoding='utf-8', errors='ignore').read().split('\\n')\n",
    "movie_conversations = open('dataset/movie_conversations.txt', encoding='utf-8', errors='ignore').read().split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['L1045 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ They do not!',\n",
       " 'L1044 +++$+++ u2 +++$+++ m0 +++$+++ CAMERON +++$+++ They do to!']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_lines[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L194', 'L195', 'L196', 'L197']\",\n",
       " \"u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L198', 'L199']\"]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_conversations[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "def generate_quesAns(file_dir): \n",
    "    '''create a list of questions (inputs) and answers (targets) from data'''\n",
    "    \n",
    "    movie_dir = os.path.join(file_dir, 'movie_lines.txt')\n",
    "    convs_dir = os.path.join(file_dir, 'movie_conversations.txt' )\n",
    "    movie_lines = open(movie_dir, encoding='utf-8', errors='ignore').read().split('\\n')\n",
    "    movie_conversations = open(convs_dir, encoding='utf-8', errors='ignore').read().split('\\n')\n",
    "    \n",
    "    id_line = {}\n",
    "    convs_ids = [ ]\n",
    "    questions = []\n",
    "    answers = []\n",
    "    \n",
    "    # a dictionary mapping line_ids and its corresponding text\n",
    "    for line in movie_lines:\n",
    "        txt = line.split(' +++$+++ ')\n",
    "        if len(txt) == 5:\n",
    "            id_line[txt[0]] = txt[4]\n",
    "    \n",
    "    # check the id_line dict\n",
    "    dict_pairs = id_line.items()\n",
    "    pairs_iterator = iter(dict_pairs)\n",
    "    first_pair = next(pairs_iterator)\n",
    "    print(f'first key_value of id_line dictionary: {first_pair}')\n",
    "    \n",
    "    \n",
    "    \n",
    "    # a list containing all the conversation line_ids\n",
    "    for line in movie_conversations[:-1]:\n",
    "        ids = line.split(' +++$+++ ')[-1][1:-1].replace(\"'\",\"\").replace(\" \",\"\")\n",
    "        convs_ids.append(ids.split(','))\n",
    "        \n",
    "    # check the convs_ids\n",
    "    print(f'the first two line of convs_ids: {convs_ids[:1]}')\n",
    "    \n",
    "    \n",
    "    \n",
    "    # create questions and answers given the list of convs_ids and the sentence corresponding to each id\n",
    "    for conv_id in convs_ids:\n",
    "        for i in range(len(conv_id)-1):\n",
    "            questions.append(id_line[conv_id[i]])\n",
    "            answers.append(id_line[conv_id[i+1]])\n",
    "            \n",
    "    return questions, answers\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first key_value of id_line dictionary: ('L1045', 'They do not!')\n",
      "the first two line of convs_ids: [['L194', 'L195', 'L196', 'L197']]\n"
     ]
    }
   ],
   "source": [
    "base_dir = './dataset'\n",
    "questions, answers = generate_quesAns(base_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(questions): 221616 & len(answers): 221616\n",
      "\n",
      "question0: Can we make this quick?  Roxanne Korrine and Andrew Barrett are having an incredibly horrendous public break- up on the quad.  Again.\n",
      "answer0: Well, I thought we'd start with pronunciation, if that's okay with you.\n",
      "\n",
      "question1: Well, I thought we'd start with pronunciation, if that's okay with you.\n",
      "answer1: Not the hacking and gagging and spitting part.  Please.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f'len(questions): {len(questions)} & len(answers): {len(answers)}\\n')\n",
    "\n",
    "for i in range(2):\n",
    "    print(f'question{i}: {questions[i]}')\n",
    "    print(f'answer{i}: {answers[i]}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycontractions import Contractions\n",
    "import gensim.downloader as api\n",
    "# Choose model accordingly for contractions function\n",
    "model = api.load(\"glove-twitter-25\")\n",
    "# model = api.load(\"glove-twitter-100\")\n",
    "# model = api.load(\"word2vec-google-news-300\")\n",
    "cont = Contractions(kv_model=model)\n",
    "cont.load_models()\n",
    "def clean_data(text):\n",
    "    \"\"\"expand shortened words, e.g. don't to do not\"\"\"\n",
    "    text = list(cont.expand_texts([text], precise=True))[0]\n",
    "    text = re.sub(r\"[-()\\\"#/@;:<>{}`+=~|.!?,]\", \"\", text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = [clean_data(ques) for ques in questions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "answers = [clean_data(ans) for ans in answers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question0: can we make this quick  roxanne korrine and andrew barrett are having an incredibly horrendous public break up on the quad  again\n",
      "answer0: well i thought we would start with pronunciation if that is okay with you\n",
      "\n",
      "question1: well i thought we would start with pronunciation if that is okay with you\n",
      "answer1: not the hacking and gagging and spitting part  please\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(2):\n",
    "    print(f'question{i}: {questions[i]}')\n",
    "    print(f'answer{i}: {answers[i]}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#only keep questions and answers within min and max # of words, and remove those shorter than min_words and \n",
    "#longer than max_words'''\n",
    "temp_questions = []\n",
    "temp_answers = []\n",
    "short_questions = []\n",
    "short_answers = []\n",
    "\n",
    "min_words = 2\n",
    "max_words = 20\n",
    "\n",
    "i = 0\n",
    "j = 0\n",
    "#remove short/long questions\n",
    "for question in questions:  \n",
    "    length = len(question.split())\n",
    "    if  length>= min_words and length <= max_words:\n",
    "        temp_questions.append(question)\n",
    "        temp_answers.append(answers[i])\n",
    "    i += 1\n",
    "\n",
    "# remove short/long answers\n",
    "for answer in temp_answers:\n",
    "    length = len(answer.split())\n",
    "    if  length>= min_words and length <= max_words:\n",
    "        short_answers.append(answer)\n",
    "        short_questions.append(temp_questions[j])\n",
    "    j += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "138335 out of 221616 questions used\n",
      "138335 out of 221616 questions used\n",
      "62.4 % of data used\n"
     ]
    }
   ],
   "source": [
    "print(f'{len(short_questions)} out of {len(questions)} questions used')\n",
    "print(f'{len(short_answers)} out of {len(answers)} questions used')\n",
    "print(f'{100*round(len(short_questions)/len(questions), 3)} % of data used')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_count(threshold, questions, answers):\n",
    "    '''create a vocabulary dictionary representing frequency of each word in corpus'''\n",
    "    '''then, remove words with counts less than threshold from vocabulary '''\n",
    "    '''then, map each word in vocabulary to an integer'''\n",
    "    \n",
    "    tokens = ['<PAD>','<UNK>','<GO>', '<EOS>']\n",
    "    vocabulary = {}\n",
    "    vocab2int = {}\n",
    "        \n",
    "    for question in questions:\n",
    "        for word in question.split():\n",
    "            vocabulary[word] = vocabulary.get(word, 0) + 1\n",
    "                \n",
    "    for answer in answers:\n",
    "        for word in answer.split():\n",
    "            vocabulary[word] = vocabulary.get(word, 0) + 1\n",
    "        answer += ' <EOS>'  #Add EOS token to the end of answer\n",
    "    \n",
    "    \n",
    "    num = 0\n",
    "    for key, value in vocabulary.items():\n",
    "        if value >= threshold:\n",
    "            vocab2int[key] = num\n",
    "            num += 1\n",
    "    \n",
    "    for tok in tokens:\n",
    "        vocab2int[tok] = len(vocab2int)+1\n",
    "        \n",
    "    \n",
    "    return vocab2int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of vocab2int dictionary:8096\n"
     ]
    }
   ],
   "source": [
    "vocab2int = word_count(10, short_questions, short_answers)\n",
    "print(f'length of vocab2int dictionary:{len(vocab2int)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of int2vocab dictionary:8096\n"
     ]
    }
   ],
   "source": [
    "int2vocab = {value:key for key,value in vocab2int.items()}\n",
    "print(f'length of int2vocab dictionary:{len(int2vocab)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#change words to ints, if word not in vocabulary, consider it as '<UNK>' word\n",
    "questions2ints, answers2ints = [], []\n",
    "for question in short_questions:\n",
    "    ints = [vocab2int[word] if word in vocab2int else vocab2int['<UNK>'] for word in question.split()]    \n",
    "    questions2ints.append(ints)\n",
    "    \n",
    "\n",
    "for answer in short_answers:\n",
    "    ints = [vocab2int[word] if word in vocab2int else vocab2int['<UNK>'] for word in answer.split()]  \n",
    "    answers2ints.append(ints)\n",
    "    \n",
    "#to reduce the amount of padding during training, & as a result speed up training and reduce the loss, I will\n",
    "# sort the questions and answers by the length of questions\n",
    "sorted_questions, sorted_answers = [], []\n",
    "for i in range(max_words):\n",
    "    length = i+1\n",
    "    for idx,val in enumerate(questions2ints):\n",
    "        if len(val) == length:\n",
    "            sorted_questions.append(questions2ints[idx])\n",
    "            sorted_answers.append(answers2ints[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the length of questions2ints: 138335, the length of sorted_questions: 138335\n",
      "the length of questions2ints: 138335, the length of sorted_answers: 138335\n"
     ]
    }
   ],
   "source": [
    "print(f'the length of questions2ints: {len(questions2ints)}, the length of sorted_questions: {len(sorted_questions)}')\n",
    "print(f'the length of questions2ints: {len(answers2ints)}, the length of sorted_answers: {len(sorted_answers)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the length of training data set: 117585\n",
      "the length of validation data set: 20750\n"
     ]
    }
   ],
   "source": [
    "split_point = int(len(questions2ints)*0.15)   #train_validation split point\n",
    "\n",
    "train_questions = sorted_questions[split_point:]\n",
    "train_answers = sorted_answers[split_point:]\n",
    "\n",
    "valid_questions = sorted_questions[:split_point]\n",
    "valid_answers = sorted_answers[:split_point]\n",
    "\n",
    "print(f'the length of training data set: {len(train_questions)}')\n",
    "print(f'the length of validation data set: {len(valid_questions)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def padding(sentences, vocab2int):\n",
    "    \"makes the length of all sentence in the batch, the same\"\n",
    "    max_length = max([len(sentence) for sentence in sentences])\n",
    "    return [sentence + [vocab2int['<PAD>']] * (max_length - len(sentence)) for sentence in sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(questions, answers, batch_size):\n",
    "    '''sample a batch of questions and answers from training data'''\n",
    "    for i in range(len(questions)//batch_size):\n",
    "        q_batch = questions[i*batch_size : (i+1)*batch_size]\n",
    "        q_batch2 = padding(q_batch, vocab2int)\n",
    "        \n",
    "        a_batch = answers[i*batch_size : (i+1)*batch_size]      \n",
    "        a_batch2 = padding(a_batch, vocab2int)\n",
    "        \n",
    "        yield np.array(q_batch2), np.array((a_batch2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   1/100 Batch    0/918 - Loss:  0.091, Seconds: 192.23\n",
      "Epoch   1/100 Batch  100/918 - Loss:  3.276, Seconds: 207.23\n",
      "Epoch   1/100 Batch  200/918 - Loss:  2.404, Seconds: 223.50\n",
      "Epoch   1/100 Batch  300/918 - Loss:  2.323, Seconds: 221.14\n",
      "Epoch   1/100 Batch  400/918 - Loss:  2.240, Seconds: 224.46\n",
      "Validation Loss:  2.178, Seconds: 102.58\n",
      "Better model found!\n",
      "Epoch   1/100 Batch  500/918 - Loss:  2.203, Seconds: 231.30\n",
      "Epoch   1/100 Batch  600/918 - Loss:  2.217, Seconds: 254.84\n",
      "Epoch   1/100 Batch  700/918 - Loss:  2.197, Seconds: 298.08\n",
      "Epoch   1/100 Batch  800/918 - Loss:  2.179, Seconds: 323.92\n",
      "Epoch   1/100 Batch  900/918 - Loss:  2.137, Seconds: 354.85\n",
      "Validation Loss:  2.118, Seconds: 114.63\n",
      "Better model found!\n",
      "Epoch   2/100 Batch    0/918 - Loss:  0.382, Seconds: 223.83\n",
      "Epoch   2/100 Batch  100/918 - Loss:  2.070, Seconds: 224.46\n",
      "Epoch   2/100 Batch  200/918 - Loss:  2.059, Seconds: 242.57\n",
      "Epoch   2/100 Batch  300/918 - Loss:  2.066, Seconds: 253.19\n",
      "Epoch   2/100 Batch  400/918 - Loss:  2.052, Seconds: 256.63\n",
      "Validation Loss:  2.026, Seconds: 113.81\n",
      "Better model found!\n",
      "Epoch   2/100 Batch  500/918 - Loss:  2.052, Seconds: 258.85\n",
      "Epoch   2/100 Batch  600/918 - Loss:  2.087, Seconds: 276.80\n",
      "Epoch   2/100 Batch  700/918 - Loss:  2.083, Seconds: 288.76\n",
      "Epoch   2/100 Batch  800/918 - Loss:  2.078, Seconds: 321.35\n",
      "Epoch   2/100 Batch  900/918 - Loss:  2.047, Seconds: 353.26\n",
      "Validation Loss:  2.036, Seconds: 112.93\n",
      "No Improvement.\n",
      "Epoch   3/100 Batch    0/918 - Loss:  0.366, Seconds: 224.56\n",
      "Epoch   3/100 Batch  100/918 - Loss:  1.994, Seconds: 228.58\n",
      "Epoch   3/100 Batch  200/918 - Loss:  1.989, Seconds: 236.74\n",
      "Epoch   3/100 Batch  300/918 - Loss:  2.003, Seconds: 232.56\n",
      "Epoch   3/100 Batch  400/918 - Loss:  1.990, Seconds: 222.46\n",
      "Validation Loss:  1.994, Seconds: 111.73\n",
      "Better model found!\n",
      "Epoch   3/100 Batch  500/918 - Loss:  1.994, Seconds: 260.26\n",
      "Epoch   3/100 Batch  600/918 - Loss:  2.034, Seconds: 284.76\n",
      "Epoch   3/100 Batch  700/918 - Loss:  2.031, Seconds: 297.07\n",
      "Epoch   3/100 Batch  800/918 - Loss:  2.029, Seconds: 321.54\n",
      "Epoch   3/100 Batch  900/918 - Loss:  2.000, Seconds: 364.81\n",
      "Validation Loss:  1.997, Seconds: 99.36\n",
      "No Improvement.\n",
      "Epoch   4/100 Batch    0/918 - Loss:  0.358, Seconds: 203.10\n",
      "Epoch   4/100 Batch  100/918 - Loss:  1.950, Seconds: 205.90\n",
      "Epoch   4/100 Batch  200/918 - Loss:  1.949, Seconds: 214.47\n",
      "Epoch   4/100 Batch  300/918 - Loss:  1.964, Seconds: 220.41\n",
      "Epoch   4/100 Batch  400/918 - Loss:  1.953, Seconds: 221.42\n",
      "Validation Loss:  1.976, Seconds: 95.86\n",
      "Better model found!\n",
      "Epoch   4/100 Batch  500/918 - Loss:  1.956, Seconds: 229.69\n",
      "Epoch   4/100 Batch  600/918 - Loss:  1.998, Seconds: 256.52\n",
      "Epoch   4/100 Batch  700/918 - Loss:  1.997, Seconds: 273.56\n",
      "Epoch   4/100 Batch  800/918 - Loss:  1.996, Seconds: 291.78\n",
      "Epoch   4/100 Batch  900/918 - Loss:  1.967, Seconds: 324.34\n",
      "Validation Loss:  1.979, Seconds: 95.31\n",
      "No Improvement.\n",
      "Epoch   5/100 Batch    0/918 - Loss:  0.353, Seconds: 205.25\n",
      "Epoch   5/100 Batch  100/918 - Loss:  1.921, Seconds: 214.70\n",
      "Epoch   5/100 Batch  200/918 - Loss:  1.921, Seconds: 220.73\n",
      "Epoch   5/100 Batch  300/918 - Loss:  1.936, Seconds: 230.26\n",
      "Epoch   5/100 Batch  400/918 - Loss:  1.925, Seconds: 225.32\n",
      "Validation Loss:  1.963, Seconds: 99.01\n",
      "Better model found!\n",
      "Epoch   5/100 Batch  500/918 - Loss:  1.929, Seconds: 293.19\n",
      "Epoch   5/100 Batch  600/918 - Loss:  1.972, Seconds: 321.75\n",
      "Epoch   5/100 Batch  700/918 - Loss:  1.969, Seconds: 329.50\n",
      "Epoch   5/100 Batch  800/918 - Loss:  1.968, Seconds: 326.91\n",
      "Epoch   5/100 Batch  900/918 - Loss:  1.942, Seconds: 406.44\n",
      "Validation Loss:  1.969, Seconds: 111.92\n",
      "No Improvement.\n",
      "Epoch   6/100 Batch    0/918 - Loss:  0.347, Seconds: 256.64\n",
      "Epoch   6/100 Batch  100/918 - Loss:  1.895, Seconds: 279.39\n",
      "Epoch   6/100 Batch  200/918 - Loss:  1.898, Seconds: 293.95\n",
      "Epoch   6/100 Batch  300/918 - Loss:  1.911, Seconds: 303.39\n",
      "Epoch   6/100 Batch  400/918 - Loss:  1.900, Seconds: 295.19\n",
      "Validation Loss:  1.955, Seconds: 112.18\n",
      "Better model found!\n",
      "Epoch   6/100 Batch  500/918 - Loss:  1.908, Seconds: 325.52\n",
      "Epoch   6/100 Batch  600/918 - Loss:  1.949, Seconds: 342.18\n",
      "Epoch   6/100 Batch  700/918 - Loss:  1.946, Seconds: 373.66\n",
      "Epoch   6/100 Batch  800/918 - Loss:  1.948, Seconds: 399.32\n",
      "Epoch   6/100 Batch  900/918 - Loss:  1.921, Seconds: 473.00\n",
      "Validation Loss:  1.962, Seconds: 118.94\n",
      "No Improvement.\n",
      "Epoch   7/100 Batch    0/918 - Loss:  0.344, Seconds: 307.81\n",
      "Epoch   7/100 Batch  100/918 - Loss:  1.878, Seconds: 306.84\n",
      "Epoch   7/100 Batch  200/918 - Loss:  1.878, Seconds: 321.73\n",
      "Epoch   7/100 Batch  300/918 - Loss:  1.890, Seconds: 329.57\n",
      "Epoch   7/100 Batch  400/918 - Loss:  1.881, Seconds: 337.42\n",
      "Validation Loss:  1.953, Seconds: 111.70\n",
      "Better model found!\n",
      "Epoch   7/100 Batch  500/918 - Loss:  1.889, Seconds: 372.98\n",
      "Epoch   7/100 Batch  600/918 - Loss:  1.930, Seconds: 378.75\n",
      "Epoch   7/100 Batch  700/918 - Loss:  1.928, Seconds: 403.09\n",
      "Epoch   7/100 Batch  800/918 - Loss:  1.928, Seconds: 429.24\n",
      "Epoch   7/100 Batch  900/918 - Loss:  1.903, Seconds: 486.84\n",
      "Validation Loss:  1.956, Seconds: 111.70\n",
      "No Improvement.\n",
      "Epoch   8/100 Batch    0/918 - Loss:  0.341, Seconds: 335.80\n",
      "Epoch   8/100 Batch  100/918 - Loss:  1.860, Seconds: 342.59\n",
      "Epoch   8/100 Batch  200/918 - Loss:  1.861, Seconds: 353.10\n",
      "Epoch   8/100 Batch  300/918 - Loss:  1.877, Seconds: 373.92\n",
      "Epoch   8/100 Batch  400/918 - Loss:  1.866, Seconds: 364.25\n",
      "Validation Loss:  1.949, Seconds: 112.79\n",
      "Better model found!\n",
      "Epoch   8/100 Batch  500/918 - Loss:  1.873, Seconds: 471.29\n",
      "Epoch   8/100 Batch  600/918 - Loss:  1.914, Seconds: 409.64\n",
      "Epoch   8/100 Batch  700/918 - Loss:  1.911, Seconds: 441.42\n",
      "Epoch   8/100 Batch  800/918 - Loss:  1.913, Seconds: 471.78\n",
      "Epoch   8/100 Batch  900/918 - Loss:  1.888, Seconds: 557.09\n",
      "Validation Loss:  1.952, Seconds: 112.46\n",
      "No Improvement.\n",
      "Epoch   9/100 Batch    0/918 - Loss:  0.338, Seconds: 384.26\n",
      "Epoch   9/100 Batch  100/918 - Loss:  1.846, Seconds: 522.40\n",
      "Epoch   9/100 Batch  200/918 - Loss:  1.845, Seconds: 473.30\n",
      "Epoch   9/100 Batch  300/918 - Loss:  1.862, Seconds: 501.15\n",
      "Epoch   9/100 Batch  400/918 - Loss:  1.851, Seconds: 448.12\n",
      "Validation Loss:  1.946, Seconds: 113.77\n",
      "Better model found!\n",
      "Epoch   9/100 Batch  500/918 - Loss:  1.859, Seconds: 486.76\n",
      "Epoch   9/100 Batch  600/918 - Loss:  1.899, Seconds: 499.05\n",
      "Epoch   9/100 Batch  700/918 - Loss:  1.897, Seconds: 565.99\n",
      "Epoch   9/100 Batch  800/918 - Loss:  1.896, Seconds: 555.11\n",
      "Epoch   9/100 Batch  900/918 - Loss:  1.874, Seconds: 631.27\n",
      "Validation Loss:  1.953, Seconds: 101.51\n",
      "No Improvement.\n",
      "Epoch  10/100 Batch    0/918 - Loss:  0.334, Seconds: 413.99\n",
      "Epoch  10/100 Batch  100/918 - Loss:  1.831, Seconds: 387.82\n",
      "Epoch  10/100 Batch  200/918 - Loss:  1.833, Seconds: 453.49\n",
      "Epoch  10/100 Batch  300/918 - Loss:  1.849, Seconds: 490.74\n",
      "Epoch  10/100 Batch  400/918 - Loss:  1.837, Seconds: 487.88\n",
      "Validation Loss:  1.947, Seconds: 110.04\n",
      "No Improvement.\n",
      "Epoch  10/100 Batch  500/918 - Loss:  1.847, Seconds: 581.81\n",
      "Epoch  10/100 Batch  600/918 - Loss:  1.885, Seconds: 442.48\n",
      "Epoch  10/100 Batch  700/918 - Loss:  1.885, Seconds: 619.99\n",
      "Epoch  10/100 Batch  800/918 - Loss:  1.883, Seconds: 524.70\n",
      "Epoch  10/100 Batch  900/918 - Loss:  1.861, Seconds: 616.32\n",
      "Validation Loss:  1.952, Seconds: 99.25\n",
      "No Improvement.\n",
      "Epoch  11/100 Batch    0/918 - Loss:  0.332, Seconds: 459.70\n",
      "Epoch  11/100 Batch  100/918 - Loss:  1.820, Seconds: 444.81\n",
      "Epoch  11/100 Batch  200/918 - Loss:  1.820, Seconds: 434.29\n",
      "Epoch  11/100 Batch  300/918 - Loss:  1.835, Seconds: 471.70\n",
      "Epoch  11/100 Batch  400/918 - Loss:  1.826, Seconds: 403.61\n",
      "Validation Loss:  1.948, Seconds: 98.19\n",
      "No Improvement.\n",
      "Epoch  11/100 Batch  500/918 - Loss:  1.833, Seconds: 452.08\n",
      "Epoch  11/100 Batch  600/918 - Loss:  1.873, Seconds: 483.40\n",
      "Epoch  11/100 Batch  700/918 - Loss:  1.872, Seconds: 559.91\n",
      "Epoch  11/100 Batch  800/918 - Loss:  1.871, Seconds: 542.01\n",
      "Epoch  11/100 Batch  900/918 - Loss:  1.850, Seconds: 656.06\n",
      "Validation Loss:  1.957, Seconds: 100.90\n",
      "No Improvement.\n",
      "Early Stopping!\n"
     ]
    }
   ],
   "source": [
    "from model import LSTM_MODEL\n",
    "\n",
    "\n",
    "lr_decay = 0.9\n",
    "min_lr = 0.0001\n",
    "early_stop = 0 \n",
    "stop = 5 \n",
    "training_loss = 0 \n",
    "validation_loss = [] \n",
    "\n",
    "\n",
    "model = LSTM_MODEL(max_words, vocab2int)\n",
    "\n",
    "\n",
    "epoch = 1\n",
    "epochs = 100\n",
    "while epoch <= epochs:\n",
    "    for batch, (questions, answers) in enumerate(sample(train_questions, train_answers, model.batch_size)):\n",
    "        start_t = time.time()\n",
    "        loss = model.fit(questions, answers)\n",
    "        training_loss += loss\n",
    "        end_t = time.time()\n",
    "        delta_t = end_t - start_t\n",
    "        \n",
    "        if batch % 100 == 0:  #every 100 batch print the training loss                            \n",
    "            print('Epoch {}/{}} Batch {}/{} - Loss: {:6.3f}, Seconds: {:6.2f}'.format(epoch,epochs, batch, \n",
    "                          len(train_questions) // model.batch_size, training_loss / 100, 100*delta_t))\n",
    "                \n",
    "            training_loss = 0\n",
    "\n",
    "        if batch % (((len(train_questions))//model.batch_size//2)-1) == 0:\n",
    "            valid_loss = 0\n",
    "            start_tt = time.time()\n",
    "            for batch_i, (questions, answers) in enumerate(sample(valid_questions, valid_answers, model.batch_size)):\n",
    "                loss = model.sess.run(model.cost, {model.input_data: questions,\n",
    "                                                   model.targets: answers,\n",
    "                                                   model.lr: model.learning_rate,\n",
    "                                                   model.sequence_length: answers.shape[1],\n",
    "                                                   model.keep_prob: 1})\n",
    "                valid_loss += loss\n",
    "            end_tt = time.time()\n",
    "            delta_tt = end_tt - start_tt\n",
    "            avg_loss = valid_loss / (len(valid_questions) / model.batch_size)\n",
    "            validation_loss.append(avg_loss)\n",
    "                  \n",
    "            print('Validation Loss: {:6.3f}, Seconds: {:6.2f}'.format(avg_loss, delta_tt))\n",
    "            \n",
    "            model.learning_rate *= lr_decay\n",
    "            model.learning_rate = min_lr if model.learning_rate < min_lr else model.learning_rate\n",
    "\n",
    "            \n",
    "            if avg_loss <= min(validation_loss):\n",
    "                print('Better model found!') \n",
    "                early_stop = 0\n",
    "                model.save()\n",
    "            else:\n",
    "                print(\"No Improvement.\")\n",
    "                early_stop += 1\n",
    "                if early_stop == stop:\n",
    "                    break\n",
    "        \n",
    "    if early_stop == stop:\n",
    "        print(\"Early Stopping!\")\n",
    "        break\n",
    "                  \n",
    "    epoch += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
